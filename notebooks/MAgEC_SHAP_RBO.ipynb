{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import site\n",
    "site.addsitedir('../src')  # Always appends to end\n",
    "import magec_utils as mg\n",
    "import mimic_utils as mimic\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp():\n",
    "    mlp = Sequential()\n",
    "    mlp.add(Dense(60, input_dim=len(xst_train.columns), activation='relu'))\n",
    "    mlp.add(Dropout(0.5))\n",
    "    mlp.add(Dense(30, input_dim=60, activation='relu'))\n",
    "    mlp.add(Dropout(0.5))\n",
    "    mlp.add(Dense(1, activation='sigmoid'))\n",
    "    mlp.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "    return mlp\n",
    "\n",
    "def impute(df):\n",
    "    df[labs] = df[labs].fillna(df[labs].mean())\n",
    "    for vital in vitals:\n",
    "        df['first_'+vital] = df['first_'+vital].fillna(df['first_'+vital].mean())\n",
    "        df['last_'+vital] = df['last_'+vital].fillna(df['last_'+vital].mean())    \n",
    "    df[comobs] = df[comobs].fillna(0)\n",
    "    return df\n",
    "\n",
    "def featurize(df, outcome):\n",
    "    out = dict()\n",
    "    for lab in labs:\n",
    "        out[lab] = last_val(df[lab])\n",
    "    for vital in vitals:\n",
    "        out['first_'+vital] = first_val(df[vital])\n",
    "        out['last_'+vital] = last_val(df[vital])\n",
    "    for comob in comobs:\n",
    "        out[comob] = last_val(df[comob])\n",
    "    for other in others:\n",
    "        out[other] = last_val(df[other])\n",
    "    out['label'] = int(df[outcome].iloc[-1])\n",
    "    return pd.Series(out)\n",
    "\n",
    "def first_val(x):\n",
    "    vals = list(x[~np.isnan(x)])\n",
    "    if len(vals):\n",
    "        return vals[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def last_val(x):\n",
    "    vals = list(x[~np.isnan(x)])\n",
    "    if len(vals):\n",
    "        return vals[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def train_valid_ml(df_ml, test_size=0.2, seed=7):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    x_cols = list(set(df_ml.columns) - {'label'})\n",
    "    y_cols = ['case', 'label']\n",
    "\n",
    "    cases = df_ml['case'].unique()\n",
    "\n",
    "    np.random.shuffle(cases)  # inplace shuffle\n",
    "\n",
    "    valid_cases = cases[:int(len(cases) * test_size)]\n",
    "    train_cases = cases[int(len(cases) * test_size):]\n",
    "\n",
    "    train_cases = np.isin(df_ml['case'], train_cases)\n",
    "    valid_cases = np.isin(df_ml['case'], valid_cases)\n",
    "\n",
    "    xy_train = df_ml.loc[train_cases, :]\n",
    "    x_train = xy_train[x_cols].copy()\n",
    "    Y_train = xy_train[y_cols].copy()\n",
    "\n",
    "    Y_train['label'] = Y_train['label'].astype(int)\n",
    "    Y_train['timepoint'] = 0\n",
    "    Y_train = Y_train.set_index(['case', 'timepoint'])\n",
    "    \n",
    "    xy_valid = df_ml.loc[valid_cases, :]\n",
    "    x_valid = xy_valid[x_cols].copy()\n",
    "    Y_valid = xy_valid[y_cols].copy()\n",
    "    \n",
    "    Y_valid['label'] = Y_valid['label'].astype(int)\n",
    "    Y_valid['timepoint'] = 0\n",
    "    Y_valid = Y_valid.set_index(['case', 'timepoint'])\n",
    "    \n",
    "    x_train = impute(x_train)\n",
    "    x_train['timepoint'] = 0\n",
    "    x_valid = impute(x_valid)\n",
    "    x_valid['timepoint'] = 0\n",
    "    \n",
    "    x_train = x_train.set_index(['case', 'timepoint'])\n",
    "    \n",
    "    x_valid = x_valid.set_index(['case', 'timepoint'])\n",
    "    \n",
    "    feats = x_train.columns\n",
    "    \n",
    "    bool_cols = [col for col in feats if df_ml[col].dropna().value_counts().index.isin([0,1]).all()]\n",
    "    non_bool_cols = [col for col in feats if col not in bool_cols]\n",
    "     \n",
    "    stsc = StandardScaler()\n",
    "    xst_train = x_train.copy()\n",
    "    xst_train[non_bool_cols] = stsc.fit_transform(x_train[non_bool_cols])\n",
    "    xst_train = pd.DataFrame(xst_train, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "    xst_valid = x_valid.copy()\n",
    "    xst_valid[non_bool_cols] = stsc.transform(x_valid[non_bool_cols])\n",
    "    xst_valid = pd.DataFrame(xst_valid, index=x_valid.index, columns=x_valid.columns)\n",
    "\n",
    "    return x_train, x_valid, stsc, xst_train, xst_valid, Y_train, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC-III\n",
    "vitals = ['heartrate_mean', 'sysbp_mean', 'diasbp_mean', 'meanbp_mean',\n",
    "          'resprate_mean', 'tempc_mean', 'spo2_mean', 'glucose_mean']\n",
    "\n",
    "labs = ['aniongap', 'albumin', 'bicarbonate', 'bilirubin', 'creatinine', \n",
    "        'chloride', 'glucose', 'hemoglobin', 'lactate', \n",
    "        'magnesium', 'phosphate', 'platelet', 'potassium', 'ptt', 'inr', \n",
    "        'pt', 'sodium', 'bun', 'wbc']  # -hematocrit\n",
    "\n",
    "comobs = ['congestive_heart_failure', 'chronic_pulmonary', 'pulmonary_circulation']\n",
    "\n",
    "others = ['age', 'gender']\n",
    "\n",
    "features = vitals+labs\n",
    "\n",
    "df_cohort = mimic.get_mimic_data()\n",
    "\n",
    "df_ml = df_cohort.rename(columns={'subject_id': 'case'})\n",
    "df_ml = df_ml.set_index(['case', 'timepoint'])\n",
    "df_ml = df_ml.sort_index(level=[0, 1], ascending=[1, 0])\n",
    "\n",
    "df_ml = df_ml.reset_index(1).groupby(level=0, group_keys=False).apply(lambda x: featurize(x, 'ventilated'))\n",
    "\n",
    "x_train, x_valid, stsc, xst_train, xst_valid, Y_train, Y_valid = train_valid_ml(df_ml.reset_index())\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(Y_train['label']),\n",
    "                                                  Y_train['label'])\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "mlp1 = KerasClassifier(build_fn=create_mlp, epochs=100, batch_size=64, verbose=0)\n",
    "mlp1.fit(xst_train, Y_train['label'], \n",
    "         epochs=100, \n",
    "         batch_size=64, \n",
    "         verbose=0, \n",
    "         class_weight={0:class_weights[0], 1:class_weights[1]}, )\n",
    "print('Built MLP1 classifier!')\n",
    "\n",
    "\n",
    "np.random.seed(321)\n",
    "python_random.seed(321)\n",
    "tf.random.set_seed(4321)\n",
    "\n",
    "mlp2 = KerasClassifier(build_fn=create_mlp, epochs=100, batch_size=64, verbose=0)\n",
    "mlp2.fit(xst_train, Y_train['label'], \n",
    "         epochs=100, \n",
    "         batch_size=64, \n",
    "         verbose=0, \n",
    "         class_weight={0:class_weights[0], 1:class_weights[1]}, )\n",
    "print('Built MLP2 classifier!')\n",
    "\n",
    "\n",
    "np.random.seed(231)\n",
    "python_random.seed(231)\n",
    "tf.random.set_seed(2314)\n",
    "\n",
    "mlp3 = KerasClassifier(build_fn=create_mlp, epochs=100, batch_size=64, verbose=0)\n",
    "mlp3.fit(xst_train, Y_train['label'], \n",
    "         epochs=100, \n",
    "         batch_size=64, \n",
    "         verbose=0, \n",
    "         class_weight={0:class_weights[0], 1:class_weights[1]}, )\n",
    "print('Built MLP3 classifier!')\n",
    "\n",
    "sv = svm.SVC(probability=True, class_weight=\"balanced\")\n",
    "sv.fit(xst_train, Y_train['label'])\n",
    "print('Built SVM classifier!')\n",
    "\n",
    "lr = LogisticRegression(C=1., class_weight='balanced', solver='lbfgs')\n",
    "lr.fit(xst_train, Y_train['label'])\n",
    "print('Built LR classifier!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAgEC Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.evaluate(mlp1, xst_valid, Y_valid['label'], verbose=True);\n",
    "mg.evaluate(mlp2, xst_valid, Y_valid['label'], verbose=True);\n",
    "mg.evaluate(mlp3, xst_valid, Y_valid['label'], verbose=True);\n",
    "mg.evaluate(sv, xst_valid, Y_valid['label'], verbose=True);\n",
    "mg.evaluate(lr, xst_valid, Y_valid['label'], verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_abnormal(x, features):\n",
    "    res = None\n",
    "    feat = None\n",
    "    for f in features:\n",
    "        if res is None or abs(x[f]) > res:\n",
    "            res = abs(x[f])\n",
    "            feat = f\n",
    "    return feat\n",
    "\n",
    "def get_magecs(m1, m2, m3, xst_valid, Ydata, baseline=None, models=('mlp1', 'mlp2', 'mlp3')):\n",
    "    \n",
    "    magecs1 = mg.case_magecs(m1, xst_valid, model_name=models[0], baseline=baseline)\n",
    "    magecs1 = mg.normalize_magecs(magecs1, features=None, model_name=models[0])\n",
    "   \n",
    "    magecs2 = mg.case_magecs(m2, xst_valid, model_name=models[1], baseline=baseline)\n",
    "    magecs2 = mg.normalize_magecs(magecs2, features=None, model_name=models[1])\n",
    "    \n",
    "    magecs3 = mg.case_magecs(m3, xst_valid, model_name=models[2], baseline=baseline)\n",
    "    magecs3 = mg.normalize_magecs(magecs3, features=None, model_name=models[2])\n",
    "    \n",
    "    feats = list(xst_valid.columns)\n",
    "    \n",
    "    joined = mg.magec_models(magecs1, magecs2, magecs3, \n",
    "                             Xdata=xst_valid, Ydata=Ydata['label'], features=feats)\n",
    "    \n",
    "    prob_cols = [c for c in joined.columns if c.startswith('perturb') and '_'.join(c.split('_')[1:-2]) in feats]\n",
    "    \n",
    "    joined['orig_prob_ensemble'] = joined[['orig_prob_'+models[0], \n",
    "                                           'orig_prob_'+models[1], \n",
    "                                           'orig_prob_'+models[2]]].apply(np.mean, 1)\n",
    "    \n",
    "    joined[['best_feat', 'new_risk', 'rank_feat', 'rank_val', 'top_rank_prob']] = joined.apply(\n",
    "        lambda x: mimic.best_feature(x, prob_cols), axis=1)\n",
    "    joined['most_abnormal'] = joined.apply(lambda x: most_abnormal(x, feats), axis=1)\n",
    "    \n",
    "    ranks = mg.magec_rank(joined, rank=len(feats), features=feats, models=models)\n",
    "    \n",
    "    rbos = mg.magec_rbos(ranks, models=models)\n",
    "    \n",
    "    if models == ('mlp1', 'mlp2', 'mlp3'):\n",
    "        rbo_cols = ['mlp2_mlp1', 'mlp3_mlp1', 'mlp3_mlp2']\n",
    "    else:\n",
    "        rbo_cols = ['mlp_lr', 'svm_lr', 'svm_mlp']\n",
    "    \n",
    "    rbos['rbo'] = rbos[rbo_cols].apply(np.mean, 1)\n",
    "    \n",
    "    consensus = mg.magec_consensus(ranks, models=models)\n",
    "    consensus = consensus.merge(rbos[['rbo', 'case']], left_on='case', right_on='case')\n",
    "    consensus = consensus.merge(Ydata.reset_index()[['case','label']], left_on='case', right_on='case')\n",
    "        \n",
    "    return joined, ranks, consensus, rbos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAgEC Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, consensus_homo, _ = get_magecs(mlp1, mlp2, mlp3, \n",
    "                                     xst_valid, Y_valid, baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, consensus_heto, _ = get_magecs(mlp3, sv, lr,  \n",
    "                                     xst_valid, Y_valid, baseline=None, \n",
    "                                     models=('mlp', 'svm', 'lr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, consensus_p5, _ = get_magecs(mlp3, sv, lr,  \n",
    "                                   xst_valid, Y_valid, baseline=0.5, \n",
    "                                   models=('mlp', 'svm', 'lr'))\n",
    "\n",
    "_, _, consensus_p3, _ = get_magecs(mlp3, sv, lr,  \n",
    "                                   xst_valid, Y_valid, baseline=0.3, \n",
    "                                   models=('mlp', 'svm', 'lr'))\n",
    "\n",
    "_, _, consensus_p1, _ = get_magecs(mlp3, sv, lr,  \n",
    "                                   xst_valid, Y_valid, baseline=0.1, \n",
    "                                   models=('mlp', 'svm', 'lr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBO Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons1 = consensus_homo[['winner','rbo']].copy()\n",
    "cons1['panel'] = 'homogeneous'\n",
    "cons2 = consensus_heto[['winner','rbo']].copy()\n",
    "cons2['panel'] = 'heterogeneous'\n",
    "cons = pd.concat([cons1, cons2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cons) == len(cons1)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rbo(df, save=''):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(12, 16))\n",
    "    order = list(df.winner.value_counts().index.values)\n",
    "    sns.barplot(x='rbo', \n",
    "                y='winner',\n",
    "                hue='panel',\n",
    "                data=df, \n",
    "                order=order,\n",
    "                palette=\"pastel\", \n",
    "                edgecolor=\".6\",\n",
    "                ci=None,\n",
    "                ax=ax);\n",
    "    ax.grid('on')\n",
    "    ax.set_title('MAgEC Average RBO')\n",
    "    ax.set_ylabel('Top MAgEC')\n",
    "    ax.set_xlabel('Average RBO from pairwise model RBOs')\n",
    "    ax.legend(['homogeneous', 'heterogeneous'], loc='lower right')\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(20)\n",
    "    if save:\n",
    "        fig.savefig(save, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rbo(cons, save='rbo_panels_comp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity(consens, title='', topK=None, save=''):\n",
    "   \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(28, 12), sharey=True)\n",
    "        \n",
    "    df = consens\n",
    "    order = list(df[(df['label']==1)&(df['perturb']=='full')][['winner']].winner.value_counts().index.values) \n",
    "    if topK is not None:\n",
    "        order =  order[:topK]\n",
    "        df = df[np.isin(df['winner'], order)]\n",
    "        \n",
    "    sns.countplot(y=\"winner\", \n",
    "                  hue=\"perturb\", \n",
    "                  palette=\"pastel\", \n",
    "                  edgecolor=\".6\",\n",
    "                  data=df[df['label']==1], \n",
    "                  order=order,\n",
    "                  ax=ax[0]);\n",
    "    \n",
    "    sns.countplot(y=\"winner\", \n",
    "                  hue=\"perturb\", \n",
    "                  palette=\"pastel\", \n",
    "                  edgecolor=\".6\",\n",
    "                  data=df[df['label']==0], \n",
    "                  order=order,\n",
    "                  ax=ax[1]);\n",
    "        \n",
    "    \n",
    "    ax[0].set_title('Label=1' + title)\n",
    "    ax[0].set_ylabel('Top Magec')\n",
    "    ax[0].grid('on')\n",
    "    \n",
    "    ax[1].set_ylabel('')\n",
    "    ax[1].set_title('Label=0' + title)\n",
    "    ax[1].grid('on')\n",
    "    \n",
    "    for item in ([ax[0].title, ax[0].xaxis.label, ax[0].yaxis.label] +\n",
    "             ax[0].get_xticklabels() + ax[0].get_yticklabels()):\n",
    "        item.set_fontsize(21)\n",
    "        \n",
    "    for item in ([ax[1].title, ax[1].xaxis.label, ax[1].yaxis.label] +\n",
    "             ax[1].get_xticklabels() + ax[1].get_yticklabels()):\n",
    "        item.set_fontsize(21)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(save, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = consensus_heto[['case','winner','label','score']].copy()\n",
    "c1['perturb'] = 'full'\n",
    "\n",
    "c2 = consensus_p5[['case','winner','label','score']].copy()\n",
    "c2['perturb'] = '0.5'\n",
    "\n",
    "c3 = consensus_p3[['case','winner','label','score']].copy()\n",
    "c3['perturb'] = '0.3'\n",
    "\n",
    "c4 = consensus_p1[['case','winner','label','score']].copy()\n",
    "c4['perturb'] = '0.1'\n",
    "\n",
    "consens = pd.concat([c1, c2, c3, c4], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(consens) == 4 * len(consensus_heto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = [col for col in list(xst_valid.columns) \n",
    "             if df_ml[col].dropna().value_counts().index.isin([0,1]).all()]\n",
    "non_bool_cols = [col for col in list(xst_valid.columns) \n",
    "                 if col not in bool_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consens = consens[np.isin(consens['winner'], non_bool_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivity(consens, topK=15, title=' (top 15 features)', save='magec_sensitivity_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAgEC Feature Importance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feat_importance(consensus, shaps, feats=None, save=''):\n",
    "    if feats is not None:\n",
    "        df = consensus[np.isin(consensus['winner'], feats)]\n",
    "    else:\n",
    "        df = consensus\n",
    "    \n",
    "    sh1 = shaps[shaps['label']==1]\n",
    "    sh0 = shaps[shaps['label']==0]\n",
    "    \n",
    "    df1 = df[df['label']==1]\n",
    "    df0 = df[df['label']==0]\n",
    "    \n",
    "    order1 = list(df1.winner.value_counts().index.values)\n",
    "    order0 = list(df0.winner.value_counts().index.values)\n",
    "    \n",
    "    a4_dims = (20, 20)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=a4_dims)\n",
    "    \n",
    "    sns.countplot(y=\"winner\", \n",
    "                  palette=\"pastel\", \n",
    "                  edgecolor=\".6\",\n",
    "                  data=df1, \n",
    "                  order=order1,\n",
    "                  ax=ax[0][0]);\n",
    "    \n",
    "    sns.countplot(y=\"winner\", \n",
    "                  palette=\"pastel\", \n",
    "                  edgecolor=\".6\",\n",
    "                  data=df0, \n",
    "                  order=order0,\n",
    "                  ax=ax[1][0]);\n",
    "\n",
    "    sns.barplot(x='shap', \n",
    "                y='feature' ,\n",
    "                data=sh1, \n",
    "                order=order1,\n",
    "                palette=\"pastel\", \n",
    "                edgecolor=\".6\",\n",
    "                ax=ax[0][1]);\n",
    "    \n",
    "    sns.barplot(x='shap', \n",
    "                y='feature' ,\n",
    "                data=sh0, \n",
    "                order=order0,\n",
    "                palette=\"pastel\", \n",
    "                edgecolor=\".6\",\n",
    "                ax=ax[1][1]);\n",
    "    \n",
    "    ax[0][0].set_title('Top MAgEC Feature for Label=1')\n",
    "    ax[1][0].set_title('Top MAgEC Feature for Label=0')\n",
    "    ax[0][0].set_ylabel('Top Magec')\n",
    "    ax[1][0].set_ylabel('Top Magec')\n",
    "    \n",
    "    ax[0][1].set_title('Feature importance using SHAP for Label=1')\n",
    "    ax[1][1].set_title('Feature importance using SHAP for Label=0')\n",
    "    ax[0][1].set_xlabel('mean(|SHAP value|)')\n",
    "    ax[1][1].set_xlabel('mean(|SHAP value|)')\n",
    "    ax[0][1].set_ylabel('')\n",
    "    ax[1][1].set_ylabel('')\n",
    "    \n",
    "    ax[0][0].grid('on')\n",
    "    ax[0][1].grid('on')\n",
    "    ax[1][0].grid('on')\n",
    "    ax[1][1].grid('on')\n",
    "        \n",
    "    for item in ([ax[0][0].title, ax[0][1].title, ax[0][0].xaxis.label, ax[0][0].yaxis.label] + \n",
    "                 [ax[1][0].title, ax[1][1].title, ax[0][1].xaxis.label, ax[0][1].yaxis.label] + \n",
    "                 [ax[1][0].xaxis.label, ax[1][0].yaxis.label, ax[1][1].xaxis.label, ax[1][1].yaxis.label] + \n",
    "                 ax[0][0].get_xticklabels() + ax[0][0].get_yticklabels() + \n",
    "                 ax[0][1].get_xticklabels() + ax[0][1].get_yticklabels() + \n",
    "                 ax[1][1].get_xticklabels() + ax[1][1].get_yticklabels() + \n",
    "                 ax[1][0].get_xticklabels() + ax[1][0].get_yticklabels()):\n",
    "        item.set_fontsize(20)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(save, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xg = xgboost.XGBClassifier(scale_pos_weight=4)\n",
    "xg.fit(xst_train, Y_train['label'])\n",
    "mg.evaluate(xg, xst_valid, Y_valid['label'], verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xg = xgboost.XGBClassifier(scale_pos_weight=4)\n",
    "xg.fit(xst_train, Y_train['label'])\n",
    "mg.evaluate(xg, xst_valid, Y_valid['label'], verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(xg)\n",
    "shap_values = explainer.shap_values(xst_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y_valid.reset_index()\n",
    "y0 = y[y['label'] == 0].index.values\n",
    "y1 = y[y['label'] == 1].index.values\n",
    "len(y0), len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh0 = shap_values[y0,:]\n",
    "sh1 = shap_values[y1,:]\n",
    "sh0.shape, sh1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaps0 = {x[1]:x[0] for x in zip(list(np.abs(sh0).mean(0)), list(xst_valid.columns))}\n",
    "shaps0 = pd.DataFrame.from_dict(shaps0, orient='index', columns=['shap']).\\\n",
    "    reset_index().rename(columns={'index': 'feature'})\n",
    "shaps0['label'] = 0\n",
    "\n",
    "shaps1 = {x[1]:x[0] for x in zip(list(np.abs(sh1).mean(0)), list(xst_valid.columns))}\n",
    "shaps1 = pd.DataFrame.from_dict(shaps1, orient='index', columns=['shap']).\\\n",
    "    reset_index().rename(columns={'index': 'feature'})\n",
    "shaps1['label'] = 1\n",
    "\n",
    "shaps = pd.concat([shaps0, shaps1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feat_importance2(consensus, shaps, feats=None, save=''):\n",
    "    if feats is not None:\n",
    "        df = consensus[np.isin(consensus['winner'], feats)]\n",
    "    else:\n",
    "        df = consensus\n",
    "    \n",
    "    sh1 = shaps[shaps['label']==1]\n",
    "    sh0 = shaps[shaps['label']==0]\n",
    "    \n",
    "    df1 = df[df['label']==1]\n",
    "    df0 = df[df['label']==0]\n",
    "    \n",
    "    order1 = list(df1.winner.value_counts().index.values)\n",
    "    order0 = list(df0.winner.value_counts().index.values)\n",
    "    \n",
    "    order1s = sh1.sort_values('shap', ascending=False)['feature'].values\n",
    "    order0s = sh0.sort_values('shap', ascending=False)['feature'].values\n",
    "    \n",
    "    a4_dims = (20, 20)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=a4_dims)\n",
    "    \n",
    "    sns.countplot(y=\"winner\", \n",
    "                  palette=\"pastel\", \n",
    "                  edgecolor=\".6\",\n",
    "                  data=df1, \n",
    "                  order=order1,\n",
    "                  ax=ax[0][0]);\n",
    "       \n",
    "    sns.countplot(y=\"winner\", \n",
    "                  palette=\"pastel\", \n",
    "                  edgecolor=\".6\",\n",
    "                  data=df0, \n",
    "                  order=order0,\n",
    "                  ax=ax[1][0]);\n",
    "\n",
    "    sns.barplot(x='shap', \n",
    "                y='feature' ,\n",
    "                data=sh1, \n",
    "                order=order1,\n",
    "                palette=\"pastel\", \n",
    "                edgecolor=\".6\",\n",
    "                ax=ax[0][1]);\n",
    "    \n",
    "    sns.barplot(x='shap', \n",
    "                y='feature' ,\n",
    "                data=sh0, \n",
    "                order=order0,\n",
    "                palette=\"pastel\", \n",
    "                edgecolor=\".6\",\n",
    "                ax=ax[1][1]);\n",
    "    \n",
    "    \n",
    "    for i, p in enumerate(ax[0][0].patches):\n",
    "        width = p.get_width()\n",
    "        y = p.get_y()\n",
    "        x = p.get_x()\n",
    "        ax[0][0].text(width+1, y+0.4,\n",
    "                 '{}'.format(1+i),\n",
    "                 ha='center', va='center', fontsize=14)\n",
    "        \n",
    "    for i, p in enumerate(ax[0][1].patches):\n",
    "        width = p.get_width()\n",
    "        y = p.get_y()\n",
    "        x = p.get_x()\n",
    "        ax[0][1].text(width+0.005, y+0.4,\n",
    "                 '{}'.format(1+np.where(order1s == order1[i])[0][0]),\n",
    "                 ha='center', va='center', fontsize=14)\n",
    "        \n",
    "    for i, p in enumerate(ax[1][0].patches):\n",
    "        width = p.get_width()\n",
    "        y = p.get_y()\n",
    "        x = p.get_x()\n",
    "        ax[1][0].text(width+6, y+0.4,\n",
    "                 '{}'.format(1+i),\n",
    "                 ha='center', va='center', fontsize=14)\n",
    "        \n",
    "    for i, p in enumerate(ax[1][1].patches):\n",
    "        width = p.get_width()\n",
    "        y = p.get_y()\n",
    "        x = p.get_x()\n",
    "        ax[1][1].text(width+0.005, y+0.4,\n",
    "                 '{}'.format(1+np.where(order0s == order0[i])[0][0]),\n",
    "                 ha='center', va='center', fontsize=14)\n",
    "    \n",
    "    ax[0][0].set_title('Top MAgEC Feature for Label=1')\n",
    "    ax[1][0].set_title('Top MAgEC Feature for Label=0')\n",
    "    ax[0][0].set_ylabel('Top Magec')\n",
    "    ax[1][0].set_ylabel('Top Magec')\n",
    "    \n",
    "    ax[0][1].set_title('Feature importance using SHAP for Label=1')\n",
    "    ax[1][1].set_title('Feature importance using SHAP for Label=0')\n",
    "    ax[0][1].set_xlabel('mean(|SHAP value|)')\n",
    "    ax[1][1].set_xlabel('mean(|SHAP value|)')\n",
    "    ax[0][1].set_ylabel('')\n",
    "    ax[1][1].set_ylabel('')\n",
    "    \n",
    "    ax[0][0].grid('on')\n",
    "    ax[0][1].grid('on')\n",
    "    ax[1][0].grid('on')\n",
    "    ax[1][1].grid('on')\n",
    "        \n",
    "    for item in ([ax[0][0].title, ax[0][1].title, ax[0][0].xaxis.label, ax[0][0].yaxis.label] + \n",
    "                 [ax[1][0].title, ax[1][1].title, ax[0][1].xaxis.label, ax[0][1].yaxis.label] + \n",
    "                 [ax[1][0].xaxis.label, ax[1][0].yaxis.label, ax[1][1].xaxis.label, ax[1][1].yaxis.label] + \n",
    "                 ax[0][0].get_xticklabels() + ax[0][0].get_yticklabels() + \n",
    "                 ax[0][1].get_xticklabels() + ax[0][1].get_yticklabels() + \n",
    "                 ax[1][1].get_xticklabels() + ax[1][1].get_yticklabels() + \n",
    "                 ax[1][0].get_xticklabels() + ax[1][0].get_yticklabels()):\n",
    "        item.set_fontsize(20)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(save, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance2(consensus_heto, shaps, save='magec_shap_comp2.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_importance(consensus_heto, shaps, save='magec_shap_comp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'creatinine' in consensus_heto.groupby(['winner'])['rbo'].mean().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'creatinine' in consensus_homo.groupby(['winner'])['rbo'].mean().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'potassium' in consensus_heto.groupby(['winner'])['rbo'].mean().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'potassium' in consensus_homo.groupby(['winner'])['rbo'].mean().index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity and Specificity\n",
    "- Sensitivity measures the proportion of positives that are correctly identified (e.g., the percentage of sick people who are correctly identified as having some illness).\n",
    "-  Specificity measures the proportion of negatives that are correctly identified (e.g., the percentage of healthy people who are correctly identified as not having some illness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.816131\n",
    "# Precision: 0.533465\n",
    "# Recall: 0.649880\n",
    "# F1 score: 0.585946\n",
    "# ROC AUC: 0.832637\n",
    "# [[1429  237]\n",
    "#  [ 146  271]]\n",
    "tn = 1429\n",
    "fp = 237\n",
    "tp = 271\n",
    "fn = 146\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('MLP ', sensitivity, specificity)\n",
    "\n",
    "# Accuracy: 0.783485\n",
    "# Precision: 0.472131\n",
    "# Recall: 0.690647\n",
    "# F1 score: 0.560857\n",
    "# ROC AUC: 0.813949\n",
    "# [[1344  322]\n",
    "#  [ 129  288]]\n",
    "tn = 1344\n",
    "fp = 322\n",
    "tp = 288\n",
    "fn = 129\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('SVM ', sensitivity, specificity)\n",
    "\n",
    "# Accuracy: 0.672588\n",
    "# Precision: 0.339782\n",
    "# Recall: 0.673861\n",
    "# F1 score: 0.451768\n",
    "# ROC AUC: 0.721519\n",
    "# [[1120  546]\n",
    "#  [ 136  281]]\n",
    "tn = 1120\n",
    "fp = 546\n",
    "tp = 281\n",
    "fn = 136\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('LR ', sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = list()\n",
    "models = ('lr', 'svm', 'mlp')\n",
    "for i,m in enumerate([lr, sv, mlp3]):\n",
    "    preds = pd.DataFrame(m.predict_proba(xst_valid)[:, 1])\n",
    "    preds.columns = [models[i] + '_prob_1']\n",
    "    others.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.concat(others + [Y_valid.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['ensemble_prob'] = preds[['lr_prob_1','svm_prob_1','mlp_prob_1']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['class_1'] = (preds['ensemble_prob'] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1, auc = mg.model_metrics(preds['ensemble_prob'],\n",
    "                                                        preds['class_1'],\n",
    "                                                        preds['label'],\n",
    "                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = 1468\n",
    "fp = 198\n",
    "tp = 254\n",
    "fn = 163\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "print('Ensemble ', sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TN', np.sum((preds['label']==0) & (preds['class_1'] == preds['label'])))\n",
    "print('FP', np.sum((preds['label']==0) & (preds['class_1'] != preds['label'])))\n",
    "print('TP', np.sum((preds['label']==1) & (preds['class_1'] == preds['label'])))\n",
    "print('FN', np.sum((preds['label']==1) & (preds['class_1'] != preds['label'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}